{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "# import MNIST (MNIST is a dataset containing correctly labeled images of handwritten numbers)\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-59ea84b5220f>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/yiliu77/Documents/Python/envs/main_env/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/yiliu77/Documents/Python/envs/main_env/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/yiliu77/Documents/Python/envs/main_env/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/yiliu77/Documents/Python/envs/main_env/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# create a variable containing MNIST data\n",
    "# There's more than 30,000 images here \n",
    "# Just imagine the man hours :P\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "# Ignore the warnings :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our parameters\n",
    "\n",
    "# How much a step we take. Higher learning rates means faster learning but less stable performance\n",
    "learning_rate = 0.001 \n",
    "# How many images we are training on at every step. \n",
    "# Remember this is gradient descent so we are gonna take small steps of just 128 images towards the goal\n",
    "batch_size = 128\n",
    "# runn 2000 steps\n",
    "n_steps = 2000\n",
    "\n",
    "# How many neurons for each layer\n",
    "n_inputs = 28 * 28 # its a 28 by 28 pixel image so input is gonna be 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_output = 10 # output is probabilities of the image being a particular number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create placeholders\n",
    "# this is where we will feed in the images and the labels\n",
    "# x is where we will feed in the image\n",
    "x = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "# y is where we will feed in the label for the corresponding image\n",
    "# i.e. if the image is a 3, y is 3\n",
    "y = tf.placeholder(tf.int64, shape=None, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the neural network\n",
    "# hidden1 layer takes in our image input (x)\n",
    "# we will be using the relu activation function\n",
    "# for more about activation functions:\n",
    "# https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f\n",
    "hidden1_layer = tf.layers.dense(x, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "hidden2_layer = tf.layers.dense(hidden1_layer, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "output_layer = tf.layers.dense(hidden2_layer, n_output, name=\"outputs\")\n",
    "# if you get some weird error about reuse, restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# instead of using squared error like the 3Blue1Brown video, we use cross entropy error\n",
    "# cross entropy is much better: https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output_layer)\n",
    "# add up all the error\n",
    "loss = tf.reduce_mean(cross_entropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use Adam Optimizer to do all the backpropagation heavy lifting for us\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
    "# create an operator that we can call on to minimize loss\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create operators for evaluating the network\n",
    "with tf.name_scope(\"eval\"):\n",
    "    # correct variable is the number of correct labels\n",
    "    correct = tf.nn.in_top_k(output_layer, y, 1)\n",
    "    # count up the number of correct labels\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.2915\n",
      "1 Test accuracy: 0.4109\n",
      "2 Test accuracy: 0.519\n",
      "3 Test accuracy: 0.6121\n",
      "4 Test accuracy: 0.6566\n",
      "5 Test accuracy: 0.6722\n",
      "6 Test accuracy: 0.6739\n",
      "7 Test accuracy: 0.6733\n",
      "8 Test accuracy: 0.6901\n",
      "9 Test accuracy: 0.718\n",
      "10 Test accuracy: 0.7409\n",
      "11 Test accuracy: 0.7583\n",
      "12 Test accuracy: 0.7766\n",
      "13 Test accuracy: 0.7854\n",
      "14 Test accuracy: 0.8028\n",
      "15 Test accuracy: 0.819\n",
      "16 Test accuracy: 0.8273\n",
      "17 Test accuracy: 0.8263\n",
      "18 Test accuracy: 0.826\n",
      "19 Test accuracy: 0.8335\n",
      "20 Test accuracy: 0.841\n",
      "21 Test accuracy: 0.8464\n",
      "22 Test accuracy: 0.8518\n",
      "23 Test accuracy: 0.8541\n",
      "24 Test accuracy: 0.8599\n",
      "25 Test accuracy: 0.8634\n",
      "26 Test accuracy: 0.8685\n",
      "27 Test accuracy: 0.8692\n",
      "28 Test accuracy: 0.8692\n",
      "29 Test accuracy: 0.8718\n",
      "30 Test accuracy: 0.8781\n",
      "31 Test accuracy: 0.8811\n",
      "32 Test accuracy: 0.8848\n",
      "33 Test accuracy: 0.889\n",
      "34 Test accuracy: 0.8896\n",
      "35 Test accuracy: 0.8917\n",
      "36 Test accuracy: 0.8933\n",
      "37 Test accuracy: 0.8923\n",
      "38 Test accuracy: 0.8879\n",
      "39 Test accuracy: 0.8884\n",
      "40 Test accuracy: 0.8896\n",
      "41 Test accuracy: 0.8902\n",
      "42 Test accuracy: 0.8893\n",
      "43 Test accuracy: 0.8934\n",
      "44 Test accuracy: 0.8985\n",
      "45 Test accuracy: 0.8971\n",
      "46 Test accuracy: 0.9003\n",
      "47 Test accuracy: 0.8981\n",
      "48 Test accuracy: 0.8917\n",
      "49 Test accuracy: 0.8875\n",
      "50 Test accuracy: 0.8917\n",
      "51 Test accuracy: 0.9027\n",
      "52 Test accuracy: 0.9043\n",
      "53 Test accuracy: 0.8985\n",
      "54 Test accuracy: 0.8918\n",
      "55 Test accuracy: 0.8869\n",
      "56 Test accuracy: 0.8906\n",
      "57 Test accuracy: 0.8973\n",
      "58 Test accuracy: 0.9043\n",
      "59 Test accuracy: 0.9077\n",
      "60 Test accuracy: 0.906\n",
      "61 Test accuracy: 0.9029\n",
      "62 Test accuracy: 0.8988\n",
      "63 Test accuracy: 0.8978\n",
      "64 Test accuracy: 0.9021\n",
      "65 Test accuracy: 0.9058\n",
      "66 Test accuracy: 0.911\n",
      "67 Test accuracy: 0.9126\n",
      "68 Test accuracy: 0.9086\n",
      "69 Test accuracy: 0.9073\n",
      "70 Test accuracy: 0.9082\n",
      "71 Test accuracy: 0.9124\n",
      "72 Test accuracy: 0.9142\n",
      "73 Test accuracy: 0.9157\n",
      "74 Test accuracy: 0.9168\n",
      "75 Test accuracy: 0.9167\n",
      "76 Test accuracy: 0.9156\n",
      "77 Test accuracy: 0.9172\n",
      "78 Test accuracy: 0.9166\n",
      "79 Test accuracy: 0.9151\n",
      "80 Test accuracy: 0.9145\n",
      "81 Test accuracy: 0.912\n",
      "82 Test accuracy: 0.9118\n",
      "83 Test accuracy: 0.9118\n",
      "84 Test accuracy: 0.9108\n",
      "85 Test accuracy: 0.9084\n",
      "86 Test accuracy: 0.9075\n",
      "87 Test accuracy: 0.9092\n",
      "88 Test accuracy: 0.9117\n",
      "89 Test accuracy: 0.9147\n"
     ]
    }
   ],
   "source": [
    "# we built the network and training stuff\n",
    "# so now lets start training the network\n",
    "\n",
    "# creates a tensorflow session data\n",
    "# the session will keep all of our values and current state of the network\n",
    "with tf.Session() as sess:\n",
    "    # first initialize the values in the network\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(n_steps):\n",
    "        # creates a batch of images and labels\n",
    "        x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        # feed in the batch of images and batch of labels\n",
    "        # and run the training operator on them\n",
    "        sess.run(training_op, feed_dict={x: x_batch, y: y_batch})\n",
    "        # feed in the test images and the test labels (which the network has never seen)\n",
    "        # and evaluate the accuracy\n",
    "        accuracy_val = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(step, \"Test accuracy:\", accuracy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch Its Accuracy Take Off Like a Rocket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
